{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa480b31-79b9-4051-b79d-4087091fe336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthias/anaconda3/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "2025-06-05 13:24:05.223690: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/matthias/anaconda3/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments,Trainer\n",
    "from transformers import AutoModel, AutoModelForSequenceClassification,AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "models = [\n",
    "    'microsoft/deberta-v3-xsmall',\n",
    "    'microsoft/deberta-v3-small',\n",
    "    'microsoft/deberta-v3-large',\n",
    "    'microsoft/deberta-v3-base',\n",
    "]\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "device = 'cuda'\n",
    "attn_implementation = 'eager'# 'sdpa' #('flash_attention_2' if device in {'cuda', 'auto'} else 'sdpa')\n",
    "torch_dtype = (torch.bfloat16 if device in {'cuda', 'auto'} else torch.float16)\n",
    "torch_dtype = torch.bfloat16\n",
    "torch_dtype = torch.float32\n",
    "\n",
    "model_id = 'microsoft/deberta-v3-base'\n",
    "model_id = 'microsoft/deberta-v3-small'\n",
    "#deberta_clf = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "deberta = AutoModelForSequenceClassification.from_pretrained(model_id, \n",
    "                                   attn_implementation=attn_implementation,\n",
    "                                   torch_dtype=torch_dtype,\n",
    "                                   num_labels=3, \n",
    "                                   )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a306f27-afe6-46ec-8b26-0e359f466de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Hello world.[SEP]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer(['Hello world.'])['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86865523-b59e-42bf-b418-d2d6f8237335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "model_inputs = tokenizer([ 'Hello world.', 'A news article.'], truncation=True, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d304ba0-1940-4753-8ebc-755739223ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import logit\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "def _class_probabilities(cumulative_probabilities):\n",
    "    P = cumulative_probabilities\n",
    "    K = P.shape[-1]+1\n",
    "    result = []\n",
    "    for k in range(K):\n",
    "        if k == 0:\n",
    "            result.append( P[:,k].unsqueeze(1) )\n",
    "        elif k < K-1:\n",
    "            result.append( (P[:,k] - P[:,k-1]).unsqueeze(1) )\n",
    "        else:\n",
    "            result.append( (1 - P[:,k-1]).unsqueeze(1) )\n",
    "    \n",
    "    result = torch.cat(result, dim=-1)\n",
    "    return result\n",
    "\n",
    "def _predict_class(cumulative_probabilities):\n",
    "    class_probabilities = _class_probabilities(cumulative_probabilities)\n",
    "    return class_probabilities.argmax(dim=-1)\n",
    "\n",
    "# define ordinal classification head\n",
    "class OrdinalRegressionHead(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_classes, link_function=nn.Sigmoid(), \n",
    "                 dtype=torch_dtype, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.linear = nn.Linear(hidden_dim, 1, bias=True)\n",
    "        \n",
    "        thresh_init = torch.tensor([0]+[1]*(num_classes-2), dtype=torch.float32)\n",
    "        self.raw_thresholds = nn.Parameter(thresh_init, requires_grad=True)\n",
    "        self.link_function = link_function\n",
    "\n",
    "        if isinstance(link_function, nn.Sigmoid):\n",
    "            self.loss_func = nn.BCEWithLogitsLoss()\n",
    "        else:\n",
    "            self.loss_func = nn.BCELoss()\n",
    "        #self = self.to(torch_dtype)\n",
    "        self.device = device\n",
    "        self = self.to(device)\n",
    "        \n",
    "    @property\n",
    "    def theta(self):\n",
    "        return torch.cumsum(self.raw_thresholds**2, dim=0)\n",
    "    \n",
    "    def forward(self, x, targets=None, verbose=False):\n",
    "        # x is the [CLS] hidden states\n",
    "        # upcast to float32 generally\n",
    "        logits = self.linear(x.to(self.raw_thresholds.dtype)).squeeze(-1)  # shape: [batch]\n",
    "        thresholds = self.theta \n",
    "        #thresholds = torch.cumsum(self.raw_thresholds**2, dim=0)\n",
    "        #thresholds = self.raw_thresholds\n",
    "        #print(thresholds)\n",
    "        logits = logits.unsqueeze(1).repeat(1, thresholds.size(0))\n",
    "        thresholds = thresholds.unsqueeze(0).repeat(logits.size(0), 1)\n",
    "        \n",
    "        #print('logits_shape', logits.shape)\n",
    "        #print('thresholds_shape', thresholds.shape)\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        threshold_logits = thresholds - logits\n",
    "        probs = self.link_function(threshold_logits)\n",
    "        \n",
    "        if targets is not None:\n",
    "            #print(targets, type(targets))\n",
    "            if not isinstance(targets, torch.Tensor):\n",
    "                targets = torch.LongTensor(targets)\n",
    "\n",
    "            targets = targets.to(x.device).unsqueeze(-1)\n",
    "            range_ = torch.arange(self.num_classes-1).unsqueeze(0).repeat_interleave(batch_size, 0).to(x.device)\n",
    "\n",
    "            #print(targets.shape, range_.shape)\n",
    "            bce_targets = (targets <= range_).to(x.dtype)\n",
    "            \n",
    "            #print(bce_targets)\n",
    "            if verbose:\n",
    "                print('targets', targets)\n",
    "                #print('range', range_)\n",
    "                print('bce_targets', bce_targets)\n",
    "                print('class probabilities', _class_probabilities(probs))\n",
    "                print('theta', self.theta)\n",
    "            \n",
    "            if isinstance(self.link_function, nn.Sigmoid):\n",
    "                # use BCEWithLogitsLoss for numerical stability\n",
    "                loss = self.loss_func(threshold_logits, bce_targets)\n",
    "            else:\n",
    "                loss = self.loss_func(probs, bce_targets)\n",
    "        else:\n",
    "            loss = None\n",
    "        \n",
    "        return threshold_logits, probs, loss\n",
    "\n",
    "\n",
    "class PretrainedModelForOrdinalSequenceClassification(nn.Module):\n",
    "    def __init__(self, model, num_classes=3, link_function=nn.Sigmoid()):\n",
    "        super(PretrainedModelForOrdinalSequenceClassification, self).__init__()\n",
    "        self.device = model.device\n",
    "        self.model = model\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_dim = model.config.hidden_size\n",
    "        self.clf_head = OrdinalRegressionHead(self.hidden_dim, \n",
    "                                              num_classes, \n",
    "                                              link_function=link_function,\n",
    "                                              dtype=torch_dtype,\n",
    "                                              device=self.model.device)\n",
    "        self.device = self.model.device\n",
    "    def gradient_checkpointing_enable(self, *args, **kwargs):\n",
    "        return self.model.gradient_checkpointing_enable(*args, **kwargs)\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
    "        targets = labels\n",
    "        dev = self.model.device\n",
    "        outputs = self.model(input_ids=input_ids.to(dev), \n",
    "                             attention_mask=attention_mask.to(dev), \n",
    "                             **kwargs)\n",
    "        x = outputs.last_hidden_state[:,0,:] # [CLS] token embedding\n",
    "        #print(x.shape)\n",
    "        threshold_logits, probs, loss = self.clf_head(x, targets=targets)\n",
    "        \n",
    "        clf_outputs = SequenceClassifierOutput(loss=loss, \n",
    "                                               logits=threshold_logits, \n",
    "                                               hidden_states=x, \n",
    "                                               attentions=outputs.attentions)\n",
    "        class_probabilities = _class_probabilities(probs)\n",
    "        class_predictions = _predict_class(probs)\n",
    "        clf_outputs.class_probabilities = class_probabilities\n",
    "        clf_outputs.predicted_class = class_predictions\n",
    "        return clf_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a76839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze embeddings\n",
    "deberta.deberta.embeddings.word_embeddings.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c33648c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f460aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d12ef4a4-3fb1-451e-89c2-689563166435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_clf = PretrainedModelForOrdinalSequenceClassification(deberta, num_classes=3)\n",
    "model_clf = deberta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcce4c73-fa7f-440a-82ef-fe6a43734041",
   "metadata": {},
   "source": [
    "### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "051e5490-d095-4d49-b248-167d5c907e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle as pkl\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "import re\n",
    "from tqdm import tqdm; tqdm.pandas()\n",
    "import os.path as op\n",
    "import os\n",
    "\n",
    "df_dataset = pd.read_csv('Dataset-framing_annotations-Llama-3.3-70B-Instruct-Turbo.csv')\n",
    "\n",
    "output_dir = f'model_training-StandardClassifier-{model_id.split(\"/\")[-1]}'\n",
    "\n",
    "# induce partitions\n",
    "try: os.makedirs(output_dir)\n",
    "except FileExistsError: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60906472-22f2-4672-8bec-02107bf09b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_ = df_dataset[['concept', 'source', 'dateTimePub', 'FRAMING_CLASS']]\n",
    "\n",
    "test_size = .025\n",
    "seed = 125\n",
    "\n",
    "try:\n",
    "    with open(op.join(output_dir, 'train_test_part.pkl'), 'rb') as file:\n",
    "        partition_ids = pkl.load(file)\n",
    "    train, val = partition_ids['train'], partition_ids['validation']\n",
    "except FileNotFoundError:\n",
    "    train, val = train_test_split(np.array(range(len(df_dataset_))), test_size=test_size, random_state=seed)\n",
    "    train, val = train.squeeze(), val.squeeze()\n",
    "    with open(op.join(output_dir, 'train_test_part.pkl'), 'wb') as file:\n",
    "        pkl.dump({'train': train, 'validation': val}, file)\n",
    "\n",
    "def shorten_to_n_words(text, n=1500):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    if len(words) <= n:\n",
    "        return text  # no truncation needed\n",
    "    \n",
    "    # Find the index where the n-th word ends\n",
    "    count = 0\n",
    "    end_index = len(text)\n",
    "    for match in re.finditer(r'\\b\\w+\\b', text):\n",
    "        count += 1\n",
    "        if count == n:\n",
    "            end_index = match.end()\n",
    "            break\n",
    "    \n",
    "    return text[:end_index].rstrip() + \"[truncated]...\"\n",
    "\n",
    "def format_prompt_with_article(title, body, max_words=2000):\n",
    "    body = shorten_to_n_words(body, n=max_words)\n",
    "    article_input = f'Title: {title}[SEP]{body}'\n",
    "    return article_input\n",
    "\n",
    "def format_prompt_from_row(row, max_words=2000):\n",
    "    return format_prompt_with_article(row.title, row.body, max_words=max_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6feaf217-ee28-4d18-a3ac-0efab0d523f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import NamedSplit, DatasetDict, load_from_disk\n",
    "\n",
    "try:\n",
    "    ds = load_from_disk(op.join(output_dir, 'train_val_dataset.ds'))\n",
    "except FileNotFoundError:\n",
    "    df_dataset_['text'] = [ format_prompt_from_row(row) for row in tqdm(df_dataset.iloc, total=len(df_dataset)) ]\n",
    "    \n",
    "    class_order = [ 'NEUTRAL', 'LOADED', 'ALARMIST' ]\n",
    "    df_dataset_['labels'] = df_dataset_.FRAMING_CLASS.progress_apply(lambda s: class_order.index(s.strip().upper()))\n",
    "        \n",
    "    ds_train = Dataset.from_pandas(df_dataset_.iloc[train], split=NamedSplit('train'))\n",
    "    ds_val = Dataset.from_pandas(df_dataset_.iloc[val], split=NamedSplit('validation'))\n",
    "    \n",
    "    #assert False\n",
    "    def get_max_length(dataset, tokenizer=tokenizer):\n",
    "        return max(len(tokenizer(example[\"text\"])[\"input_ids\"]) for example in tqdm(dataset))\n",
    "    \n",
    "    #max_length = max(get_max_length(ds_train), get_max_length(ds_val))\n",
    "    max_length = 1500\n",
    "    \n",
    "    print('max length of:', max_length)\n",
    "    \n",
    "    # Tokenize with static padding\n",
    "    def tokenize_row(example, max_length=max_length, padding='max_length'):\n",
    "        tok = tokenizer(example[\"text\"], padding=padding, truncation=True, max_length=max_length)\n",
    "        #print(tok['input_ids'])\n",
    "        #print(len(tok['input_ids'][0]), len(tokenizer(example['text'])['input_ids'][0]))\n",
    "        return tok\n",
    "    \n",
    "    tok_train = lambda ex: tokenize_row(ex, padding='longest')\n",
    "    tok_val = tok_train # lambda ex: tokenize_row(ex, padding='max_length')\n",
    "    \n",
    "    ds_train = ds_train.map(tok_train, batched=True, batch_size=1, num_proc=1)\n",
    "    ds_val = ds_val.map(tok_val, batched=True, batch_size=1, num_proc=1)\n",
    "    \n",
    "    ds = DatasetDict({'train': ds_train, 'val': ds_val})\n",
    "    \n",
    "    ds.save_to_disk(op.join(output_dir, 'train_val_dataset.ds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7efb14d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#tokenizer.decode(tok_train(ds_train[1])['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd4238f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00c0f8db-18f7-4f0e-b693-40c4583f2527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 2/121888 [00:00<05:56, 341.46it/s]\n"
     ]
    }
   ],
   "source": [
    "ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "ds_train, ds_val = ds['train'], ds['val']\n",
    "\n",
    "#ds_train = ds['train']\n",
    "lens_ = []\n",
    "for ex in tqdm(ds_train):\n",
    "    l = len(ex['input_ids'])\n",
    "    lens_.append(l)\n",
    "    if l != 1500:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d338612-9ddc-434c-9a03-07f059c8573a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1500])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7284a513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/anaconda3/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/matthias/anaconda3/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from datasets import load_metric\n",
    "import evaluate\n",
    "from transformers import Trainer\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 1\n",
    "eval_batch_size = 1\n",
    "gradient_accumulation_steps = 5\n",
    "\n",
    "save_steps = 2_500\n",
    "eval_steps = save_steps\n",
    "\n",
    "#eval_steps = 5\n",
    "\n",
    "Num_train_examples = len(ds_train)\n",
    "optim = \"paged_adamw_32bit\"\n",
    "learning_rate = .005\n",
    "weight_decay=.00001\n",
    "gradient_checkpointing = False\n",
    "warmup_steps = 1_000\n",
    "\n",
    "\n",
    "num_epochs = 5\n",
    "max_steps = int(Num_train_examples/(batch_size*gradient_accumulation_steps)*num_epochs)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    max_steps=max_steps,\n",
    "    #num_train_epochs=EPOCHS,\n",
    "    eval_steps=eval_steps,\n",
    "    save_steps=save_steps, \n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    load_best_model_at_end=True,\n",
    "    weight_decay=weight_decay,\n",
    "    #optim=optim, \n",
    "    lr_scheduler_type='linear',\n",
    "    warmup_steps=warmup_steps,\n",
    "    gradient_checkpointing=gradient_checkpointing,\n",
    ")\n",
    "\n",
    "\n",
    "class OrdinalTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        #labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        #logits = outputs[0][:, 0]\n",
    "        #loss = torch.nn.functional.mse_loss(logits, labels)\n",
    "        loss = outputs.loss\n",
    "        if num_items_in_batch is not None:\n",
    "            loss = loss / num_items_in_batch\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def compute_per_class_metrics(preds, targets, num_classes=None):\n",
    "    \"\"\"\n",
    "    Computes precision, recall, and F1 for each class.\n",
    "    \n",
    "    Args:\n",
    "        preds: np.ndarray of shape (N,), predicted class indices\n",
    "        targets: np.ndarray of shape (N,), ground-truth class indices\n",
    "        num_classes: int, total number of classes (optional if all classes are present in data)\n",
    "\n",
    "    Returns:\n",
    "        metrics: dict with precision, recall, and f1 arrays of shape (num_classes,)\n",
    "    \"\"\"\n",
    "    if num_classes is None:\n",
    "        num_classes = max(np.max(preds), np.max(targets)) + 1\n",
    "    \n",
    "    precision = np.zeros(num_classes)\n",
    "    recall = np.zeros(num_classes)\n",
    "    f1 = np.zeros(num_classes)\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        tp = np.sum((preds == cls) & (targets == cls))\n",
    "        fp = np.sum((preds == cls) & (targets != cls))\n",
    "        fn = np.sum((preds != cls) & (targets == cls))\n",
    "        #print(cls, tp, fp, fn)\n",
    "    \n",
    "        precision[cls] = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall[cls] = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        if precision[cls] + recall[cls] > 0:\n",
    "            f1[cls] = 2 * precision[cls] * recall[cls] / (precision[cls] + recall[cls])\n",
    "        else:\n",
    "            f1[cls] = 0.0\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "def _predict_class(logits):\n",
    "    return logits.argmax(dim=-1)\n",
    "\n",
    "def compute_metrics(eval_pred, num_classes=3):\n",
    "    logits, labels = eval_pred\n",
    "    #print(eval_pred)\n",
    "    #print('logits', logits)\n",
    "    #print('labels', labels)\n",
    "    #print(logits, labels)\n",
    "\n",
    "    #print(logits[0].shape, logits[1].shape)\n",
    "    logits = logits\n",
    "    #predictions = np.argmax(logits, axis=-1)\n",
    "    with torch.no_grad():\n",
    "        predictions = _predict_class(torch.sigmoid(torch.tensor(logits))).detach().cpu().numpy()\n",
    "    \n",
    "    result = metric.compute(predictions=predictions, references=labels) # dict with 'accuracy'\n",
    "    # partition the labels by targets and measure accuracy for each to ensure balance\n",
    "    per_class_metrics = compute_per_class_metrics(predictions, labels, num_classes=num_classes)\n",
    "    for cls in range(num_classes):\n",
    "        for metric_name in [ 'precision', 'recall', 'f1' ]:\n",
    "            metric_label = f'class{cls}_{metric_name}'\n",
    "            result[metric_label] = per_class_metrics[metric_name][cls]\n",
    "    \n",
    "    return result\n",
    "\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class EvaluateAtStepOneCallback(TrainerCallback):\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        if state.global_step == 1:\n",
    "            control.should_evaluate = True\n",
    "        return control\n",
    "\n",
    "#model_clf.model.enable_input_requires_grad()\n",
    "from torch.optim import AdamW, Adam, SGD\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW([ p for p in model_clf.parameters() if p.requires_grad ], \n",
    "                  lr=learning_rate, weight_decay=weight_decay, )\n",
    "#optimizer = SGD([ model_clf.clf_head.raw_thresholds, ], lr=1, weight_decay=0.)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, max_steps, -1).step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29e638f1-5f4d-4c02-bf10-684462550b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_clf,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_val, #.select(range(1000)),\n",
    "    compute_metrics=compute_metrics,\n",
    "    #callbacks=[EvaluateAtStepOneCallback()],\n",
    "    optimizers=(optimizer, scheduler), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3731c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pre = model_clf.deberta.embeddings.word_embeddings.weight.detach().cpu().to(torch.float32).numpy()\n",
    "pre_pre_l = model_clf.deberta.encoder.layer[1].attention.self.query_proj.weight.detach().cpu().to(torch.float32).numpy()\n",
    "#pre_pre_t = model_clf.clf_head.raw_thresholds.detach().cpu().to(torch.float32).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf8c3bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0228, -0.0561,  0.0037,  ..., -0.0331, -0.0807,  0.0085],\n",
       "        [-0.0046, -0.0472, -0.0507,  ..., -0.0559,  0.0323, -0.0345],\n",
       "        [-0.0071, -0.0496, -0.0181,  ..., -0.0386,  0.0396, -0.0109],\n",
       "        ...,\n",
       "        [ 0.0078, -0.0848, -0.1141,  ..., -0.0290,  0.0598,  0.0235],\n",
       "        [ 0.0417,  0.0168, -0.1043,  ..., -0.0065,  0.0377, -0.0613],\n",
       "        [ 0.0190, -0.0188,  0.0533,  ..., -0.0762,  0.0179, -0.0594]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clf.deberta.encoder.layer[1].attention.self.query_proj.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0252ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatthias-lalisse\u001b[0m (\u001b[33mmatthias-lalisse-inet\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matthias/projects/NewsSentiment/wandb/run-20250605_132427-nwmarrp4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/matthias-lalisse-inet/huggingface/runs/nwmarrp4' target=\"_blank\">model_training-StandardClassifier-deberta-v3-small</a></strong> to <a href='https://wandb.ai/matthias-lalisse-inet/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matthias-lalisse-inet/huggingface' target=\"_blank\">https://wandb.ai/matthias-lalisse-inet/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matthias-lalisse-inet/huggingface/runs/nwmarrp4' target=\"_blank\">https://wandb.ai/matthias-lalisse-inet/huggingface/runs/nwmarrp4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='121888' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    34/121888 01:18 < 82:36:36, 0.41 it/s, Epoch 0.00/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ckpt = op.join(output_dir, 'checkpoint-10000')\n",
    "trainer.train(resume_from_checkpoint=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bca6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c30d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc8be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f0e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e216866c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10c5db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09bfa6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1253])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_val[10]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d438b929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2533fb74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b9608d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdeb0a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8ac5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e1eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49fba03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.model.get_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce238041",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(optimizer.param_groups[0]['params']):\n",
    "    if p is model_clf.clf_head.raw_thresholds:\n",
    "        state = optimizer.state[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b527c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d432b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "model_clf.clf_head.raw_thresholds.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec12956",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.raw_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccdfbdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ex in tqdm(ds_train):\n",
    "    if ex['labels'] == 2: break\n",
    "\n",
    "inputs = { k: x.unsqueeze(0).cuda() for k, x in ex.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2690998a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ex['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0879d53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb83943",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model_clf(**inputs)\n",
    "#loss = o.loss\n",
    "#loss = o.logits.sum()\n",
    "loss = model_clf.clf_head.raw_thresholds.sum()\n",
    "loss.backward()\n",
    "\n",
    "with torch.no_grad():\n",
    "    before = model_clf.clf_head.raw_thresholds.clone().detach().cpu().numpy()\n",
    "    #loss.backward()\n",
    "    optimizer.step()\n",
    "    after = model_clf.clf_head.raw_thresholds.clone().detach().cpu().numpy()\n",
    "    print('grad', model_clf.clf_head.raw_thresholds.grad)\n",
    "    print(\"delta:\", after - before)\n",
    "    #optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ex in tqdm(ds_train):\n",
    "    if ex['labels'] == 2: break\n",
    "\n",
    "inputs = { k: x.unsqueeze(0).cuda() for k, x in ex.items() }\n",
    "\n",
    "o = model_clf(**inputs)\n",
    "#loss = o.loss\n",
    "#loss = o.logits.sum()\n",
    "loss = model_clf.clf_head.raw_thresholds.sum()\n",
    "loss.backward()\n",
    "\n",
    "with torch.no_grad():\n",
    "    before = model_clf.clf_head.raw_thresholds.clone().detach().cpu().numpy()\n",
    "    #loss.backward()\n",
    "    optimizer.step()\n",
    "    after = model_clf.clf_head.raw_thresholds.clone().detach().cpu().numpy()\n",
    "    print('grad', model_clf.clf_head.raw_thresholds.grad)\n",
    "    print(\"delta:\", after - before)\n",
    "    #optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b418cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in optimizer.param_groups:\n",
    "    for p in group[\"params\"]:\n",
    "        print(\"match:\", id(p) == id(model_clf.clf_head.raw_thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a813687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c819dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef3032c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ea694",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c62be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27185b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d1a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534a3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(after - before)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a96a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.dtype, model_clf.clf_head.raw_thresholds.data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bfff89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d72e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.raw_thresholds.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0621ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c02e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.loss.backward()\n",
    "model_clf.clf_head.raw_thresholds.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc554158",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd2d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.raw_thresholds.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a32a33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_clf.clf_head.raw_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pre_t - model_clf.clf_head.raw_thresholds.detach().cpu().to(torch.float32).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed9bb60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d77c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c774f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in optimizer.param_groups[0]['params']: print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab103e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer == trainer.optimizer.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec43a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690ad9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.raw_thresholds.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1182a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.raw_thresholds.detach().cpu().to(torch.float32).numpy() - post_post_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_post = model_clf.model.embeddings.word_embeddings.weight.detach().cpu().to(torch.float32).numpy()\n",
    "post_post_l = model_clf.model.encoder.layer[1].attention.self.query_proj.weight.detach().cpu().to(torch.float32).numpy()\n",
    "post_post_t = model_clf.clf_head.raw_thresholds.detach().cpu().to(torch.float32).numpy()\n",
    "\n",
    "pre_pre - post_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0651f881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef34b001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a93b3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "post_post_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc6f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pre_t - post_post_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965bea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(post_post_l - pre_pre_l).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d712a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_post_t - pre_pre_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c78573",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_post_t, pre_pre_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094308de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df36b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.optimizer.optimizer.parameter_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55628c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87979f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b023cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64adaf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.raw_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37caa3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f946c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9a4d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f37a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d86b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c150f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3724ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = trainer.optimizer\n",
    "\n",
    "for i, group in enumerate(optimizer.param_groups):\n",
    "    print(f\"Group {i}: lr={group['lr']} | {len(group['params'])} params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dbb964",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(optimizer.param_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babc267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba93410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f3a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.optimizer.optimizer.parameter_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8516ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bdd061",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.raw_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c665d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb754b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe591e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099b8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58369675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e9cf57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068d9e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train[10000]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c747ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be71495d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da3d6f-a547-40db-b503-f94e435ac92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada8fb66-227b-4647-8377-bdc38bf5beb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1228aab-7ca3-40f1-b3ad-e9ac81d73c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5ca8c8-bdef-484f-950a-5a7627646035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a882547a-6784-4f1e-8a05-b31b426eb35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8310e40a-1e34-4ef3-a0e6-2678bc90e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.iloc[val].FRAMING_CLASS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7e831-3fef-4cab-a1a9-5331faa3b98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002610fa-bea1-4624-a08d-03d199998b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9def06-86d1-4014-b97d-e18b7ad428d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c999f2e7-eb95-462a-aafd-4987a3e7f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a9bd4a-5674-4262-8747-250095b4596a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac76ec-3d1b-4907-bd40-1b0a471d416b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28331fc5-37a4-450a-bf45-74fb5b0e0e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63881f9a-408d-403a-9fc6-651114e6948e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cee4a5-3157-4b47-86c4-487401e1ac10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d913ef-47d3-4308-adb2-5f3546c90815",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794750dc-868d-4b88-934d-aaef5679d567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b609aab6-f5d5-4c03-a626-b4ac1857b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(op.join(output_dir, 'train_val_dataset.ds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc298935-9ed8-4f9c-8ae6-f05575878e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a3aa97-4235-497d-81c5-fe28612416fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4bb258-6f1a-4487-982c-9d03bee40836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b020f-3684-45fd-9628-8cb3e97e5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import list_metrics\n",
    "list_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c871a-0ec1-4bb1-81dc-bdedf92215cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_device_train_batch_size = 1\n",
    "per_device_eval_batch_size=1\n",
    "gradient_accumulation_steps = 5 # @@CH\n",
    "optim = \"paged_adamw_8bit\"\n",
    "save_steps = 500\n",
    "logging_steps = 5\n",
    "learning_rate = 1e-4\n",
    "max_grad_norm = 0.3\n",
    "max_steps = 30_000\n",
    "warmup_ratio = 0.01\n",
    "lr_scheduler_type = \"linear\"\n",
    "eval_steps = 500\n",
    "\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    #dataset_text_field=\"text\",\n",
    "    max_seq_length=max_input_len+100,\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    fp16=True,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=True, #False,#True,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    gradient_checkpointing=True, # @@@@checkpoint\n",
    "    report_to=None,\n",
    "    do_eval=True, #@@@\n",
    "    eval_strategy='steps', #@@@\n",
    "    eval_steps=eval_steps,\n",
    "    #load_best_model_at_end=False,\n",
    "    logging_first_step=True,\n",
    "    #use_cache=False, \n",
    "    #padding_free=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf22ca8-65b3-426e-b607-712b341e1e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65be6eb-b0c4-49f7-9ad4-5631c5c0b692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb6420-4990-40f2-9fc8-756827145958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7cd1ca-cccb-4938-b522-cee5c4e3418f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed887aa-9142-4b9f-9b77-ce9a874dc20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c165816-3d13-490c-9068-732dc57e9213",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f019c91-10ec-42b6-802e-6c857eb3b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import NamedSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f726e-91c2-40e4-8d97-7d3f7218a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6b58ef-3f18-4ec3-a914-de698a1fc6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_.class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb70333-539f-4632-b0e2-6aba8916e472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b244467a-bcd8-4c9c-9bc7-6551c3ba81eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.FRAMING_CLASS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56741774-6319-4bd3-8402-4ee573b7ea73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b0a37f-b6d8-4a30-8492-5906a62a3468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cee19e-7a5d-4b77-917a-3a14a3e772a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e3c9f-942a-40d2-bad3-1ad3a5871432",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d675ba-01cd-4f45-9b43-fa1dd31b182f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b508c-c96d-4b5a-83d6-13eca8ac04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = deberta_clf(**model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd29fb73-809a-479d-b907-e0b8a5b3bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.class_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae07c805-4ec2-43c2-bdb7-ee5505e2f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_clf.clf_head.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a1de65-28ee-4cc6-a085-2a0ac53d52c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_clf.clf_head.raw_thresholds = nn.Parameter(torch.tensor([-1.,2.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38895d25-2025-4c19-9611-79b2882570e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2dfc4-e026-41a9-9a93-a2398ccea8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0391abc-9143-42b5-835f-f2bebb47edfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73358b82-3e87-40c9-a0b3-303e114d54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9ec038-6463-4186-b216-e71ed783a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.class_probabilities.sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d477f-2bbe-4698-9739-0fb3260a6854",
   "metadata": {},
   "outputs": [],
   "source": [
    "op.last_hidden_state[:,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3261cd-387b-40fe-8db6-5659df6f7310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers.modeling_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a1a62c-6ae8-4de4-9a27-23c33e3ceb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_clf.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d24e9b-6923-4959-aea5-0e59ecb8aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(deberta_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f61639a-0f84-49e7-a58f-f3468c83e768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e91a2e-262e-4cf4-971d-8510e1d67f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da35b324-bcac-443f-93a5-8c01425f09a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b66ccc-f535-4331-8799-2b6dc396a29c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
