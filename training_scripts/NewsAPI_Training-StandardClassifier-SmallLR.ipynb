{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa480b31-79b9-4051-b79d-4087091fe336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/matthias/anaconda3/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "2025-06-09 18:56:17.486020: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-xsmall and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/matthias/anaconda3/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments,Trainer\n",
    "from transformers import AutoModel, AutoModelForSequenceClassification,AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "models = [\n",
    "    'microsoft/deberta-v3-xsmall',\n",
    "    'microsoft/deberta-v3-small',\n",
    "    'microsoft/deberta-v3-large',\n",
    "    'microsoft/deberta-v3-base',\n",
    "]\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "device = 'cuda'\n",
    "attn_implementation = 'eager'# 'sdpa' #('flash_attention_2' if device in {'cuda', 'auto'} else 'sdpa')\n",
    "torch_dtype = (torch.bfloat16 if device in {'cuda', 'auto'} else torch.float16)\n",
    "torch_dtype = torch.bfloat16\n",
    "torch_dtype = torch.float32\n",
    "\n",
    "model_id = 'microsoft/deberta-v3-base'\n",
    "model_id = 'microsoft/deberta-v3-small'\n",
    "model_id = 'microsoft/deberta-v3-xsmall'\n",
    "#deberta_clf = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "deberta = AutoModelForSequenceClassification.from_pretrained(model_id, \n",
    "                                   attn_implementation=attn_implementation,\n",
    "                                   torch_dtype=torch_dtype,\n",
    "                                   num_labels=3, \n",
    "                                   )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a306f27-afe6-46ec-8b26-0e359f466de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Hello world.[SEP]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer(['Hello world.'])['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86865523-b59e-42bf-b418-d2d6f8237335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "model_inputs = tokenizer([ 'Hello world.', 'A news article.'], truncation=True, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d304ba0-1940-4753-8ebc-755739223ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import logit\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "def _class_probabilities(cumulative_probabilities):\n",
    "    P = cumulative_probabilities\n",
    "    K = P.shape[-1]+1\n",
    "    result = []\n",
    "    for k in range(K):\n",
    "        if k == 0:\n",
    "            result.append( P[:,k].unsqueeze(1) )\n",
    "        elif k < K-1:\n",
    "            result.append( (P[:,k] - P[:,k-1]).unsqueeze(1) )\n",
    "        else:\n",
    "            result.append( (1 - P[:,k-1]).unsqueeze(1) )\n",
    "    \n",
    "    result = torch.cat(result, dim=-1)\n",
    "    return result\n",
    "\n",
    "def _predict_class(cumulative_probabilities):\n",
    "    class_probabilities = _class_probabilities(cumulative_probabilities)\n",
    "    return class_probabilities.argmax(dim=-1)\n",
    "\n",
    "# define ordinal classification head\n",
    "class OrdinalRegressionHead(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_classes, link_function=nn.Sigmoid(), \n",
    "                 dtype=torch_dtype, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.linear = nn.Linear(hidden_dim, 1, bias=True)\n",
    "        \n",
    "        thresh_init = torch.tensor([0]+[1]*(num_classes-2), dtype=torch.float32)\n",
    "        self.raw_thresholds = nn.Parameter(thresh_init, requires_grad=True)\n",
    "        self.link_function = link_function\n",
    "\n",
    "        if isinstance(link_function, nn.Sigmoid):\n",
    "            self.loss_func = nn.BCEWithLogitsLoss()\n",
    "        else:\n",
    "            self.loss_func = nn.BCELoss()\n",
    "        #self = self.to(torch_dtype)\n",
    "        self.device = device\n",
    "        self = self.to(device)\n",
    "        \n",
    "    @property\n",
    "    def theta(self):\n",
    "        return torch.cumsum(self.raw_thresholds**2, dim=0)\n",
    "    \n",
    "    def forward(self, x, targets=None, verbose=False):\n",
    "        # x is the [CLS] hidden states\n",
    "        # upcast to float32 generally\n",
    "        logits = self.linear(x.to(self.raw_thresholds.dtype)).squeeze(-1)  # shape: [batch]\n",
    "        thresholds = self.theta \n",
    "        #thresholds = torch.cumsum(self.raw_thresholds**2, dim=0)\n",
    "        #thresholds = self.raw_thresholds\n",
    "        #print(thresholds)\n",
    "        logits = logits.unsqueeze(1).repeat(1, thresholds.size(0))\n",
    "        thresholds = thresholds.unsqueeze(0).repeat(logits.size(0), 1)\n",
    "        \n",
    "        #print('logits_shape', logits.shape)\n",
    "        #print('thresholds_shape', thresholds.shape)\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        threshold_logits = thresholds - logits\n",
    "        probs = self.link_function(threshold_logits)\n",
    "        \n",
    "        if targets is not None:\n",
    "            #print(targets, type(targets))\n",
    "            if not isinstance(targets, torch.Tensor):\n",
    "                targets = torch.LongTensor(targets)\n",
    "\n",
    "            targets = targets.to(x.device).unsqueeze(-1)\n",
    "            range_ = torch.arange(self.num_classes-1).unsqueeze(0).repeat_interleave(batch_size, 0).to(x.device)\n",
    "\n",
    "            #print(targets.shape, range_.shape)\n",
    "            bce_targets = (targets <= range_).to(x.dtype)\n",
    "            \n",
    "            #print(bce_targets)\n",
    "            if verbose:\n",
    "                print('targets', targets)\n",
    "                #print('range', range_)\n",
    "                print('bce_targets', bce_targets)\n",
    "                print('class probabilities', _class_probabilities(probs))\n",
    "                print('theta', self.theta)\n",
    "            \n",
    "            if isinstance(self.link_function, nn.Sigmoid):\n",
    "                # use BCEWithLogitsLoss for numerical stability\n",
    "                loss = self.loss_func(threshold_logits, bce_targets)\n",
    "            else:\n",
    "                loss = self.loss_func(probs, bce_targets)\n",
    "        else:\n",
    "            loss = None\n",
    "        \n",
    "        return threshold_logits, probs, loss\n",
    "\n",
    "\n",
    "class PretrainedModelForOrdinalSequenceClassification(nn.Module):\n",
    "    def __init__(self, model, num_classes=3, link_function=nn.Sigmoid()):\n",
    "        super(PretrainedModelForOrdinalSequenceClassification, self).__init__()\n",
    "        self.device = model.device\n",
    "        self.model = model\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_dim = model.config.hidden_size\n",
    "        self.clf_head = OrdinalRegressionHead(self.hidden_dim, \n",
    "                                              num_classes, \n",
    "                                              link_function=link_function,\n",
    "                                              dtype=torch_dtype,\n",
    "                                              device=self.model.device)\n",
    "        self.device = self.model.device\n",
    "    def gradient_checkpointing_enable(self, *args, **kwargs):\n",
    "        return self.model.gradient_checkpointing_enable(*args, **kwargs)\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
    "        targets = labels\n",
    "        dev = self.model.device\n",
    "        outputs = self.model(input_ids=input_ids.to(dev), \n",
    "                             attention_mask=attention_mask.to(dev), \n",
    "                             **kwargs)\n",
    "        x = outputs.last_hidden_state[:,0,:] # [CLS] token embedding\n",
    "        #print(x.shape)\n",
    "        threshold_logits, probs, loss = self.clf_head(x, targets=targets)\n",
    "        \n",
    "        clf_outputs = SequenceClassifierOutput(loss=loss, \n",
    "                                               logits=threshold_logits, \n",
    "                                               hidden_states=x, \n",
    "                                               attentions=outputs.attentions)\n",
    "        class_probabilities = _class_probabilities(probs)\n",
    "        class_predictions = _predict_class(probs)\n",
    "        clf_outputs.class_probabilities = class_probabilities\n",
    "        clf_outputs.predicted_class = class_predictions\n",
    "        return clf_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a76839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze embeddings\n",
    "deberta.deberta.embeddings.word_embeddings.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c33648c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 384, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (classifier): Linear(in_features=384, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f460aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d12ef4a4-3fb1-451e-89c2-689563166435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_clf = PretrainedModelForOrdinalSequenceClassification(deberta, num_classes=3)\n",
    "model_clf = deberta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcce4c73-fa7f-440a-82ef-fe6a43734041",
   "metadata": {},
   "source": [
    "### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "051e5490-d095-4d49-b248-167d5c907e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle as pkl\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "import re\n",
    "from tqdm import tqdm; tqdm.pandas()\n",
    "import os.path as op\n",
    "import os\n",
    "\n",
    "df_dataset = pd.read_csv('Dataset-framing_annotations-Llama-3.3-70B-Instruct-Turbo.csv')\n",
    "\n",
    "output_dir = f'model_training-StandardClassifierSmallLR-{model_id.split(\"/\")[-1]}'\n",
    "\n",
    "# induce partitions\n",
    "try: os.makedirs(output_dir)\n",
    "except FileExistsError: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60906472-22f2-4672-8bec-02107bf09b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_ = df_dataset[['concept', 'source', 'dateTimePub', 'FRAMING_CLASS']]\n",
    "\n",
    "test_size = .025\n",
    "seed = 125\n",
    "\n",
    "try:\n",
    "    with open(op.join(output_dir, 'train_test_part.pkl'), 'rb') as file:\n",
    "        partition_ids = pkl.load(file)\n",
    "    train, val = partition_ids['train'], partition_ids['validation']\n",
    "except FileNotFoundError:\n",
    "    train, val = train_test_split(np.array(range(len(df_dataset_))), test_size=test_size, random_state=seed)\n",
    "    train, val = train.squeeze(), val.squeeze()\n",
    "    with open(op.join(output_dir, 'train_test_part.pkl'), 'wb') as file:\n",
    "        pkl.dump({'train': train, 'validation': val}, file)\n",
    "\n",
    "def shorten_to_n_words(text, n=1500):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    if len(words) <= n:\n",
    "        return text  # no truncation needed\n",
    "    \n",
    "    # Find the index where the n-th word ends\n",
    "    count = 0\n",
    "    end_index = len(text)\n",
    "    for match in re.finditer(r'\\b\\w+\\b', text):\n",
    "        count += 1\n",
    "        if count == n:\n",
    "            end_index = match.end()\n",
    "            break\n",
    "    \n",
    "    return text[:end_index].rstrip() + \"[truncated]...\"\n",
    "\n",
    "def format_prompt_with_article(title, body, max_words=2000):\n",
    "    body = shorten_to_n_words(body, n=max_words)\n",
    "    article_input = f'Title: {title}[SEP]{body}'\n",
    "    return article_input\n",
    "\n",
    "def format_prompt_from_row(row, max_words=2000):\n",
    "    return format_prompt_with_article(row.title, row.body, max_words=max_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6feaf217-ee28-4d18-a3ac-0efab0d523f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import NamedSplit, DatasetDict, load_from_disk\n",
    "\n",
    "try:\n",
    "    ds = load_from_disk(op.join(output_dir, 'train_val_dataset.ds'))\n",
    "except FileNotFoundError:\n",
    "    df_dataset_['text'] = [ format_prompt_from_row(row) for row in tqdm(df_dataset.iloc, total=len(df_dataset)) ]\n",
    "    \n",
    "    class_order = [ 'NEUTRAL', 'LOADED', 'ALARMIST' ]\n",
    "    df_dataset_['labels'] = df_dataset_.FRAMING_CLASS.progress_apply(lambda s: class_order.index(s.strip().upper()))\n",
    "        \n",
    "    ds_train = Dataset.from_pandas(df_dataset_.iloc[train], split=NamedSplit('train'))\n",
    "    ds_val = Dataset.from_pandas(df_dataset_.iloc[val], split=NamedSplit('validation'))\n",
    "    \n",
    "    #assert False\n",
    "    def get_max_length(dataset, tokenizer=tokenizer):\n",
    "        return max(len(tokenizer(example[\"text\"])[\"input_ids\"]) for example in tqdm(dataset))\n",
    "    \n",
    "    #max_length = max(get_max_length(ds_train), get_max_length(ds_val))\n",
    "    max_length = 1500\n",
    "    \n",
    "    print('max length of:', max_length)\n",
    "    \n",
    "    # Tokenize with static padding\n",
    "    def tokenize_row(example, max_length=max_length, padding='max_length'):\n",
    "        tok = tokenizer(example[\"text\"], padding=padding, truncation=True, max_length=max_length)\n",
    "        #print(tok['input_ids'])\n",
    "        #print(len(tok['input_ids'][0]), len(tokenizer(example['text'])['input_ids'][0]))\n",
    "        return tok\n",
    "    \n",
    "    tok_train = lambda ex: tokenize_row(ex, padding='longest')\n",
    "    tok_val = tok_train # lambda ex: tokenize_row(ex, padding='max_length')\n",
    "    \n",
    "    ds_train = ds_train.map(tok_train, batched=True, batch_size=1, num_proc=1)\n",
    "    ds_val = ds_val.map(tok_val, batched=True, batch_size=1, num_proc=1)\n",
    "    \n",
    "    ds = DatasetDict({'train': ds_train, 'val': ds_val})\n",
    "    \n",
    "    ds.save_to_disk(op.join(output_dir, 'train_val_dataset.ds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7efb14d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#tokenizer.decode(tok_train(ds_train[1])['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd4238f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00c0f8db-18f7-4f0e-b693-40c4583f2527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 2/121888 [00:00<03:34, 568.18it/s]\n"
     ]
    }
   ],
   "source": [
    "ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "ds_train, ds_val = ds['train'], ds['val']\n",
    "\n",
    "#ds_train = ds['train']\n",
    "lens_ = []\n",
    "for ex in tqdm(ds_train):\n",
    "    l = len(ex['input_ids'])\n",
    "    lens_.append(l)\n",
    "    if l != 1500:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d338612-9ddc-434c-9a03-07f059c8573a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1500])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7284a513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/anaconda3/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/matthias/anaconda3/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from datasets import load_metric\n",
    "import evaluate\n",
    "from transformers import Trainer\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 1\n",
    "eval_batch_size = 1\n",
    "gradient_accumulation_steps = 5\n",
    "\n",
    "save_steps = 2_500\n",
    "eval_steps = save_steps\n",
    "\n",
    "#eval_steps = 5\n",
    "\n",
    "Num_train_examples = len(ds_train)\n",
    "optim = \"paged_adamw_32bit\"\n",
    "learning_rate = 1e-5#.005\n",
    "weight_decay= 0#.00001\n",
    "gradient_checkpointing = False\n",
    "warmup_steps = 1_000\n",
    "\n",
    "\n",
    "num_epochs = 15\n",
    "max_steps = int(Num_train_examples/(batch_size*gradient_accumulation_steps)*num_epochs)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    max_steps=max_steps,\n",
    "    max_grad_norm=50.,\n",
    "    #num_train_epochs=EPOCHS,\n",
    "    eval_steps=eval_steps,\n",
    "    save_steps=save_steps, \n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    load_best_model_at_end=True,\n",
    "    weight_decay=weight_decay,\n",
    "    #optim=optim, \n",
    "    lr_scheduler_type='linear',\n",
    "    warmup_steps=warmup_steps,\n",
    "    gradient_checkpointing=gradient_checkpointing,\n",
    ")\n",
    "\n",
    "\n",
    "class OrdinalTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        #labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        #logits = outputs[0][:, 0]\n",
    "        #loss = torch.nn.functional.mse_loss(logits, labels)\n",
    "        loss = outputs.loss\n",
    "        if num_items_in_batch is not None:\n",
    "            loss = loss / num_items_in_batch\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def compute_per_class_metrics(preds, targets, num_classes=None):\n",
    "    \"\"\"\n",
    "    Computes precision, recall, and F1 for each class.\n",
    "    \n",
    "    Args:\n",
    "        preds: np.ndarray of shape (N,), predicted class indices\n",
    "        targets: np.ndarray of shape (N,), ground-truth class indices\n",
    "        num_classes: int, total number of classes (optional if all classes are present in data)\n",
    "\n",
    "    Returns:\n",
    "        metrics: dict with precision, recall, and f1 arrays of shape (num_classes,)\n",
    "    \"\"\"\n",
    "    if num_classes is None:\n",
    "        num_classes = max(np.max(preds), np.max(targets)) + 1\n",
    "    \n",
    "    precision = np.zeros(num_classes)\n",
    "    recall = np.zeros(num_classes)\n",
    "    f1 = np.zeros(num_classes)\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        tp = np.sum((preds == cls) & (targets == cls))\n",
    "        fp = np.sum((preds == cls) & (targets != cls))\n",
    "        fn = np.sum((preds != cls) & (targets == cls))\n",
    "        #print(cls, tp, fp, fn)\n",
    "    \n",
    "        precision[cls] = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall[cls] = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        if precision[cls] + recall[cls] > 0:\n",
    "            f1[cls] = 2 * precision[cls] * recall[cls] / (precision[cls] + recall[cls])\n",
    "        else:\n",
    "            f1[cls] = 0.0\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "def _predict_class(logits):\n",
    "    return logits.argmax(dim=-1)\n",
    "\n",
    "def compute_metrics(eval_pred, num_classes=3):\n",
    "    logits, labels = eval_pred\n",
    "    #print(eval_pred)\n",
    "    #print('logits', logits)\n",
    "    #print('labels', labels)\n",
    "    #print(logits, labels)\n",
    "\n",
    "    #print(logits[0].shape, logits[1].shape)\n",
    "    logits = logits\n",
    "    #predictions = np.argmax(logits, axis=-1)\n",
    "    with torch.no_grad():\n",
    "        predictions = _predict_class(torch.sigmoid(torch.tensor(logits))).detach().cpu().numpy()\n",
    "    \n",
    "    result = metric.compute(predictions=predictions, references=labels) # dict with 'accuracy'\n",
    "    # partition the labels by targets and measure accuracy for each to ensure balance\n",
    "    per_class_metrics = compute_per_class_metrics(predictions, labels, num_classes=num_classes)\n",
    "    for cls in range(num_classes):\n",
    "        for metric_name in [ 'precision', 'recall', 'f1' ]:\n",
    "            metric_label = f'class{cls}_{metric_name}'\n",
    "            result[metric_label] = per_class_metrics[metric_name][cls]\n",
    "    \n",
    "    return result\n",
    "\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class EvaluateAtStepOneCallback(TrainerCallback):\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        if state.global_step == 1:\n",
    "            control.should_evaluate = True\n",
    "        return control\n",
    "\n",
    "#model_clf.model.enable_input_requires_grad()\n",
    "from torch.optim import AdamW, Adam, SGD\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW([ p for p in model_clf.parameters() if p.requires_grad ], \n",
    "                  lr=learning_rate, weight_decay=weight_decay, )\n",
    "#optimizer = SGD([ model_clf.clf_head.raw_thresholds, ], lr=1, weight_decay=0.)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, max_steps, -1).step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29e638f1-5f4d-4c02-bf10-684462550b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_clf,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_val, #.select(range(1000)),\n",
    "    compute_metrics=compute_metrics,\n",
    "    #callbacks=[EvaluateAtStepOneCallback()],\n",
    "    optimizers=(optimizer, scheduler), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3731c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pre = model_clf.deberta.embeddings.word_embeddings.weight.detach().cpu().to(torch.float32).numpy()\n",
    "pre_pre_l = model_clf.deberta.encoder.layer[1].attention.self.query_proj.weight.detach().cpu().to(torch.float32).numpy()\n",
    "#pre_pre_t = model_clf.clf_head.raw_thresholds.detach().cpu().to(torch.float32).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf8c3bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0213,  0.0244, -0.3035,  ..., -0.0818,  0.0801, -0.2236],\n",
       "        [ 0.3567, -0.0761, -0.0009,  ...,  0.1059, -0.0573,  0.0448],\n",
       "        [-0.1027, -0.0442,  0.0193,  ...,  0.0282,  0.2102,  0.1320],\n",
       "        ...,\n",
       "        [-0.0829, -0.0483, -0.0480,  ...,  0.0344,  0.0036, -0.0932],\n",
       "        [ 0.0728,  0.1213, -0.1473,  ..., -0.0896, -0.0208, -0.1312],\n",
       "        [ 0.1752,  0.1418,  0.1919,  ...,  0.0189,  0.1738,  0.1304]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clf.deberta.encoder.layer[1].attention.self.query_proj.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "808b7f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_RESUME'] = 'must'\n",
    "os.environ['WANDB_RUN_ID'] = 'xp5ilvcy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed685cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatthias-lalisse\u001b[0m (\u001b[33mmatthias-lalisse-inet\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matthias/projects/NewsSentiment/wandb/run-20250609_185642-xp5ilvcy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/matthias-lalisse-inet/huggingface/runs/xp5ilvcy' target=\"_blank\">model_training-StandardClassifierSmallLR-deberta-v3-xsmall</a></strong> to <a href='https://wandb.ai/matthias-lalisse-inet/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matthias-lalisse-inet/huggingface' target=\"_blank\">https://wandb.ai/matthias-lalisse-inet/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matthias-lalisse-inet/huggingface/runs/xp5ilvcy' target=\"_blank\">https://wandb.ai/matthias-lalisse-inet/huggingface/runs/xp5ilvcy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73165' max='365664' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 73165/365664 4:12:44 < 389:32:55, 0.21 it/s, Epoch 3.00/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Class0 Precision</th>\n",
       "      <th>Class0 Recall</th>\n",
       "      <th>Class0 F1</th>\n",
       "      <th>Class1 Precision</th>\n",
       "      <th>Class1 Recall</th>\n",
       "      <th>Class1 F1</th>\n",
       "      <th>Class2 Precision</th>\n",
       "      <th>Class2 Recall</th>\n",
       "      <th>Class2 F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>72500</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.265984</td>\n",
       "      <td>0.895074</td>\n",
       "      <td>0.946480</td>\n",
       "      <td>0.929451</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.792026</td>\n",
       "      <td>0.857643</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.636943</td>\n",
       "      <td>0.711744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ckpt = op.join(output_dir, 'checkpoint-70000')\n",
    "trainer.train(resume_from_checkpoint=ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63c116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842440f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99abd3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd301517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatthias-lalisse\u001b[0m (\u001b[33mmatthias-lalisse-inet\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matthias/projects/NewsSentiment/wandb/run-20250609_011822-xp5ilvcy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/matthias-lalisse-inet/huggingface/runs/xp5ilvcy' target=\"_blank\">model_training-StandardClassifierSmallLR-deberta-v3-xsmall</a></strong> to <a href='https://wandb.ai/matthias-lalisse-inet/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matthias-lalisse-inet/huggingface' target=\"_blank\">https://wandb.ai/matthias-lalisse-inet/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matthias-lalisse-inet/huggingface/runs/xp5ilvcy' target=\"_blank\">https://wandb.ai/matthias-lalisse-inet/huggingface/runs/xp5ilvcy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90187' max='365664' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 90187/365664 16:36:21 < 151:33:01, 0.50 it/s, Epoch 3.70/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Class0 Precision</th>\n",
       "      <th>Class0 Recall</th>\n",
       "      <th>Class0 F1</th>\n",
       "      <th>Class1 Precision</th>\n",
       "      <th>Class1 Recall</th>\n",
       "      <th>Class1 F1</th>\n",
       "      <th>Class2 Precision</th>\n",
       "      <th>Class2 Recall</th>\n",
       "      <th>Class2 F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>62500</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.293485</td>\n",
       "      <td>0.888676</td>\n",
       "      <td>0.945358</td>\n",
       "      <td>0.925663</td>\n",
       "      <td>0.935407</td>\n",
       "      <td>0.797069</td>\n",
       "      <td>0.824971</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.738854</td>\n",
       "      <td>0.707317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.194400</td>\n",
       "      <td>0.290214</td>\n",
       "      <td>0.889635</td>\n",
       "      <td>0.909051</td>\n",
       "      <td>0.970170</td>\n",
       "      <td>0.938617</td>\n",
       "      <td>0.845347</td>\n",
       "      <td>0.752625</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.554140</td>\n",
       "      <td>0.654135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67500</td>\n",
       "      <td>0.215500</td>\n",
       "      <td>0.286112</td>\n",
       "      <td>0.889635</td>\n",
       "      <td>0.914711</td>\n",
       "      <td>0.959754</td>\n",
       "      <td>0.936691</td>\n",
       "      <td>0.828784</td>\n",
       "      <td>0.779463</td>\n",
       "      <td>0.803367</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.547771</td>\n",
       "      <td>0.659004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.208500</td>\n",
       "      <td>0.273236</td>\n",
       "      <td>0.894114</td>\n",
       "      <td>0.929564</td>\n",
       "      <td>0.949811</td>\n",
       "      <td>0.939578</td>\n",
       "      <td>0.817330</td>\n",
       "      <td>0.814469</td>\n",
       "      <td>0.815897</td>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.579618</td>\n",
       "      <td>0.671587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ckpt = op.join(output_dir, 'checkpoint-60000')\n",
    "trainer.train(resume_from_checkpoint=ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c16f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83638bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ff331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b128414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatthias-lalisse\u001b[0m (\u001b[33mmatthias-lalisse-inet\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matthias/projects/NewsSentiment/wandb/run-20250607_223032-xp5ilvcy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/matthias-lalisse-inet/huggingface/runs/xp5ilvcy' target=\"_blank\">model_training-StandardClassifierSmallLR-deberta-v3-xsmall</a></strong> to <a href='https://wandb.ai/matthias-lalisse-inet/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matthias-lalisse-inet/huggingface' target=\"_blank\">https://wandb.ai/matthias-lalisse-inet/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matthias-lalisse-inet/huggingface/runs/xp5ilvcy' target=\"_blank\">https://wandb.ai/matthias-lalisse-inet/huggingface/runs/xp5ilvcy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65880' max='365664' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 65880/365664 24:48:28 < 181:55:54, 0.46 it/s, Epoch 2.70/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Class0 Precision</th>\n",
       "      <th>Class0 Recall</th>\n",
       "      <th>Class0 F1</th>\n",
       "      <th>Class1 Precision</th>\n",
       "      <th>Class1 Recall</th>\n",
       "      <th>Class1 F1</th>\n",
       "      <th>Class2 Precision</th>\n",
       "      <th>Class2 Recall</th>\n",
       "      <th>Class2 F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.277200</td>\n",
       "      <td>0.283701</td>\n",
       "      <td>0.889955</td>\n",
       "      <td>0.920860</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.936715</td>\n",
       "      <td>0.821385</td>\n",
       "      <td>0.788798</td>\n",
       "      <td>0.804762</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.592357</td>\n",
       "      <td>0.678832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.317294</td>\n",
       "      <td>0.882278</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.936080</td>\n",
       "      <td>0.932767</td>\n",
       "      <td>0.806804</td>\n",
       "      <td>0.774796</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.664773</td>\n",
       "      <td>0.745223</td>\n",
       "      <td>0.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.246600</td>\n",
       "      <td>0.294688</td>\n",
       "      <td>0.888676</td>\n",
       "      <td>0.934628</td>\n",
       "      <td>0.934186</td>\n",
       "      <td>0.934407</td>\n",
       "      <td>0.805330</td>\n",
       "      <td>0.810968</td>\n",
       "      <td>0.808140</td>\n",
       "      <td>0.723684</td>\n",
       "      <td>0.700637</td>\n",
       "      <td>0.711974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.258100</td>\n",
       "      <td>0.294108</td>\n",
       "      <td>0.891875</td>\n",
       "      <td>0.922477</td>\n",
       "      <td>0.952178</td>\n",
       "      <td>0.937092</td>\n",
       "      <td>0.825455</td>\n",
       "      <td>0.794632</td>\n",
       "      <td>0.809750</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.611465</td>\n",
       "      <td>0.690647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>0.281200</td>\n",
       "      <td>0.293011</td>\n",
       "      <td>0.888356</td>\n",
       "      <td>0.945631</td>\n",
       "      <td>0.922348</td>\n",
       "      <td>0.933845</td>\n",
       "      <td>0.773013</td>\n",
       "      <td>0.862310</td>\n",
       "      <td>0.815223</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.573248</td>\n",
       "      <td>0.674157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.256200</td>\n",
       "      <td>0.296146</td>\n",
       "      <td>0.889315</td>\n",
       "      <td>0.909700</td>\n",
       "      <td>0.963542</td>\n",
       "      <td>0.935847</td>\n",
       "      <td>0.840412</td>\n",
       "      <td>0.761960</td>\n",
       "      <td>0.799266</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.585987</td>\n",
       "      <td>0.684015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>0.239500</td>\n",
       "      <td>0.285557</td>\n",
       "      <td>0.895074</td>\n",
       "      <td>0.935651</td>\n",
       "      <td>0.943182</td>\n",
       "      <td>0.939401</td>\n",
       "      <td>0.807736</td>\n",
       "      <td>0.828471</td>\n",
       "      <td>0.817972</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.611465</td>\n",
       "      <td>0.698182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.263200</td>\n",
       "      <td>0.306710</td>\n",
       "      <td>0.881318</td>\n",
       "      <td>0.949729</td>\n",
       "      <td>0.912405</td>\n",
       "      <td>0.930693</td>\n",
       "      <td>0.776561</td>\n",
       "      <td>0.827305</td>\n",
       "      <td>0.801130</td>\n",
       "      <td>0.646739</td>\n",
       "      <td>0.757962</td>\n",
       "      <td>0.697947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>0.254700</td>\n",
       "      <td>0.302406</td>\n",
       "      <td>0.887076</td>\n",
       "      <td>0.907877</td>\n",
       "      <td>0.965909</td>\n",
       "      <td>0.935994</td>\n",
       "      <td>0.833119</td>\n",
       "      <td>0.757293</td>\n",
       "      <td>0.793399</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.535032</td>\n",
       "      <td>0.653696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.214200</td>\n",
       "      <td>0.313085</td>\n",
       "      <td>0.888036</td>\n",
       "      <td>0.943424</td>\n",
       "      <td>0.923769</td>\n",
       "      <td>0.933493</td>\n",
       "      <td>0.781148</td>\n",
       "      <td>0.841307</td>\n",
       "      <td>0.810112</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.662420</td>\n",
       "      <td>0.712329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52500</td>\n",
       "      <td>0.188900</td>\n",
       "      <td>0.343755</td>\n",
       "      <td>0.895713</td>\n",
       "      <td>0.915398</td>\n",
       "      <td>0.968277</td>\n",
       "      <td>0.941095</td>\n",
       "      <td>0.854922</td>\n",
       "      <td>0.770128</td>\n",
       "      <td>0.810313</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.605096</td>\n",
       "      <td>0.685921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.219900</td>\n",
       "      <td>0.288944</td>\n",
       "      <td>0.893474</td>\n",
       "      <td>0.939135</td>\n",
       "      <td>0.935133</td>\n",
       "      <td>0.937129</td>\n",
       "      <td>0.796909</td>\n",
       "      <td>0.842474</td>\n",
       "      <td>0.819058</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.611465</td>\n",
       "      <td>0.700730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57500</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.350804</td>\n",
       "      <td>0.894754</td>\n",
       "      <td>0.907367</td>\n",
       "      <td>0.973958</td>\n",
       "      <td>0.939484</td>\n",
       "      <td>0.871099</td>\n",
       "      <td>0.749125</td>\n",
       "      <td>0.805521</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.624204</td>\n",
       "      <td>0.702509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.327708</td>\n",
       "      <td>0.881958</td>\n",
       "      <td>0.932052</td>\n",
       "      <td>0.941761</td>\n",
       "      <td>0.936882</td>\n",
       "      <td>0.828608</td>\n",
       "      <td>0.750292</td>\n",
       "      <td>0.787508</td>\n",
       "      <td>0.578704</td>\n",
       "      <td>0.796178</td>\n",
       "      <td>0.670241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint-25000\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/trainer.py:2240\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/trainer.py:2555\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2548\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2549\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2551\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2553\u001b[0m )\n\u001b[1;32m   2554\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2555\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2558\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2559\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2560\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2561\u001b[0m ):\n\u001b[1;32m   2562\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2563\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/trainer.py:3745\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3744\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3745\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3747\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3749\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3750\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3751\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/trainer.py:3810\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3808\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3809\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3810\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1114\u001b[0m, in \u001b[0;36mDebertaV2ForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1114\u001b[0m     label_index \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1115\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m label_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ckpt = op.join(output_dir, 'checkpoint-25000')\n",
    "trainer.train(resume_from_checkpoint=ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4e3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d780233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101f0dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f996c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b98177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0252ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatthias-lalisse\u001b[0m (\u001b[33mmatthias-lalisse-inet\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matthias/projects/NewsSentiment/wandb/run-20250606_021939-xp5ilvcy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/matthias-lalisse-inet/huggingface/runs/xp5ilvcy' target=\"_blank\">model_training-StandardClassifierSmallLR-deberta-v3-xsmall</a></strong> to <a href='https://wandb.ai/matthias-lalisse-inet/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matthias-lalisse-inet/huggingface' target=\"_blank\">https://wandb.ai/matthias-lalisse-inet/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matthias-lalisse-inet/huggingface/runs/xp5ilvcy' target=\"_blank\">https://wandb.ai/matthias-lalisse-inet/huggingface/runs/xp5ilvcy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32813' max='365664' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 32813/365664 20:52:33 < 211:46:29, 0.44 it/s, Epoch 1.35/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Class0 Precision</th>\n",
       "      <th>Class0 Recall</th>\n",
       "      <th>Class0 F1</th>\n",
       "      <th>Class1 Precision</th>\n",
       "      <th>Class1 Recall</th>\n",
       "      <th>Class1 F1</th>\n",
       "      <th>Class2 Precision</th>\n",
       "      <th>Class2 Recall</th>\n",
       "      <th>Class2 F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.525200</td>\n",
       "      <td>0.541941</td>\n",
       "      <td>0.805822</td>\n",
       "      <td>0.947056</td>\n",
       "      <td>0.830019</td>\n",
       "      <td>0.884683</td>\n",
       "      <td>0.600784</td>\n",
       "      <td>0.893816</td>\n",
       "      <td>0.718574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.453400</td>\n",
       "      <td>0.493655</td>\n",
       "      <td>0.852207</td>\n",
       "      <td>0.882867</td>\n",
       "      <td>0.956439</td>\n",
       "      <td>0.918182</td>\n",
       "      <td>0.761665</td>\n",
       "      <td>0.704784</td>\n",
       "      <td>0.732121</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.254777</td>\n",
       "      <td>0.396040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.461900</td>\n",
       "      <td>0.429608</td>\n",
       "      <td>0.844530</td>\n",
       "      <td>0.931085</td>\n",
       "      <td>0.901989</td>\n",
       "      <td>0.916306</td>\n",
       "      <td>0.742169</td>\n",
       "      <td>0.718786</td>\n",
       "      <td>0.730290</td>\n",
       "      <td>0.476000</td>\n",
       "      <td>0.757962</td>\n",
       "      <td>0.584767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.427300</td>\n",
       "      <td>0.490577</td>\n",
       "      <td>0.856686</td>\n",
       "      <td>0.936064</td>\n",
       "      <td>0.887311</td>\n",
       "      <td>0.911035</td>\n",
       "      <td>0.703244</td>\n",
       "      <td>0.859977</td>\n",
       "      <td>0.773753</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.426752</td>\n",
       "      <td>0.575107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.409600</td>\n",
       "      <td>0.444643</td>\n",
       "      <td>0.875240</td>\n",
       "      <td>0.898095</td>\n",
       "      <td>0.959754</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.847339</td>\n",
       "      <td>0.705951</td>\n",
       "      <td>0.770210</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.662420</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.392100</td>\n",
       "      <td>0.531862</td>\n",
       "      <td>0.852527</td>\n",
       "      <td>0.951738</td>\n",
       "      <td>0.868371</td>\n",
       "      <td>0.908146</td>\n",
       "      <td>0.702729</td>\n",
       "      <td>0.841307</td>\n",
       "      <td>0.765799</td>\n",
       "      <td>0.635838</td>\n",
       "      <td>0.700637</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.389400</td>\n",
       "      <td>0.392205</td>\n",
       "      <td>0.885157</td>\n",
       "      <td>0.929742</td>\n",
       "      <td>0.939867</td>\n",
       "      <td>0.934777</td>\n",
       "      <td>0.810386</td>\n",
       "      <td>0.782964</td>\n",
       "      <td>0.796439</td>\n",
       "      <td>0.680982</td>\n",
       "      <td>0.707006</td>\n",
       "      <td>0.693750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.443447</td>\n",
       "      <td>0.879079</td>\n",
       "      <td>0.916206</td>\n",
       "      <td>0.942235</td>\n",
       "      <td>0.929038</td>\n",
       "      <td>0.795943</td>\n",
       "      <td>0.778296</td>\n",
       "      <td>0.787021</td>\n",
       "      <td>0.784483</td>\n",
       "      <td>0.579618</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.410200</td>\n",
       "      <td>0.452266</td>\n",
       "      <td>0.870761</td>\n",
       "      <td>0.949424</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.922852</td>\n",
       "      <td>0.736308</td>\n",
       "      <td>0.847141</td>\n",
       "      <td>0.787846</td>\n",
       "      <td>0.699301</td>\n",
       "      <td>0.636943</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.337400</td>\n",
       "      <td>0.528345</td>\n",
       "      <td>0.864363</td>\n",
       "      <td>0.950630</td>\n",
       "      <td>0.893466</td>\n",
       "      <td>0.921162</td>\n",
       "      <td>0.733542</td>\n",
       "      <td>0.819137</td>\n",
       "      <td>0.773980</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.719745</td>\n",
       "      <td>0.662757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.375500</td>\n",
       "      <td>0.452819</td>\n",
       "      <td>0.883877</td>\n",
       "      <td>0.909744</td>\n",
       "      <td>0.959280</td>\n",
       "      <td>0.933856</td>\n",
       "      <td>0.813268</td>\n",
       "      <td>0.772462</td>\n",
       "      <td>0.792340</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.477707</td>\n",
       "      <td>0.619835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.342600</td>\n",
       "      <td>0.457110</td>\n",
       "      <td>0.883877</td>\n",
       "      <td>0.932861</td>\n",
       "      <td>0.934186</td>\n",
       "      <td>0.933523</td>\n",
       "      <td>0.803828</td>\n",
       "      <td>0.784131</td>\n",
       "      <td>0.793857</td>\n",
       "      <td>0.674286</td>\n",
       "      <td>0.751592</td>\n",
       "      <td>0.710843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ckpt = op.join(output_dir, 'checkpoint-25000')\n",
    "trainer.train(resume_from_checkpoint=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bca6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c30d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc8be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f0e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e216866c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10c5db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09bfa6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1253])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_val[10]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d438b929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2533fb74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b9608d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdeb0a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8ac5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e1eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49fba03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.model.get_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce238041",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(optimizer.param_groups[0]['params']):\n",
    "    if p is model_clf.clf_head.raw_thresholds:\n",
    "        state = optimizer.state[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b527c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d432b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "model_clf.clf_head.raw_thresholds.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec12956",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.raw_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccdfbdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ex in tqdm(ds_train):\n",
    "    if ex['labels'] == 2: break\n",
    "\n",
    "inputs = { k: x.unsqueeze(0).cuda() for k, x in ex.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2690998a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ex['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0879d53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb83943",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model_clf(**inputs)\n",
    "#loss = o.loss\n",
    "#loss = o.logits.sum()\n",
    "loss = model_clf.clf_head.raw_thresholds.sum()\n",
    "loss.backward()\n",
    "\n",
    "with torch.no_grad():\n",
    "    before = model_clf.clf_head.raw_thresholds.clone().detach().cpu().numpy()\n",
    "    #loss.backward()\n",
    "    optimizer.step()\n",
    "    after = model_clf.clf_head.raw_thresholds.clone().detach().cpu().numpy()\n",
    "    print('grad', model_clf.clf_head.raw_thresholds.grad)\n",
    "    print(\"delta:\", after - before)\n",
    "    #optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ex in tqdm(ds_train):\n",
    "    if ex['labels'] == 2: break\n",
    "\n",
    "inputs = { k: x.unsqueeze(0).cuda() for k, x in ex.items() }\n",
    "\n",
    "o = model_clf(**inputs)\n",
    "#loss = o.loss\n",
    "#loss = o.logits.sum()\n",
    "loss = model_clf.clf_head.raw_thresholds.sum()\n",
    "loss.backward()\n",
    "\n",
    "with torch.no_grad():\n",
    "    before = model_clf.clf_head.raw_thresholds.clone().detach().cpu().numpy()\n",
    "    #loss.backward()\n",
    "    optimizer.step()\n",
    "    after = model_clf.clf_head.raw_thresholds.clone().detach().cpu().numpy()\n",
    "    print('grad', model_clf.clf_head.raw_thresholds.grad)\n",
    "    print(\"delta:\", after - before)\n",
    "    #optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b418cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in optimizer.param_groups:\n",
    "    for p in group[\"params\"]:\n",
    "        print(\"match:\", id(p) == id(model_clf.clf_head.raw_thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a813687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c819dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef3032c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ea694",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c62be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27185b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d1a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534a3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(after - before)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a96a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.dtype, model_clf.clf_head.raw_thresholds.data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bfff89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d72e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.raw_thresholds.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0621ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c02e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.loss.backward()\n",
    "model_clf.clf_head.raw_thresholds.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc554158",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd2d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.raw_thresholds.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a32a33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_clf.clf_head.raw_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pre_t - model_clf.clf_head.raw_thresholds.detach().cpu().to(torch.float32).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed9bb60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d77c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c774f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in optimizer.param_groups[0]['params']: print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab103e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer == trainer.optimizer.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec43a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690ad9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.raw_thresholds.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1182a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.raw_thresholds.detach().cpu().to(torch.float32).numpy() - post_post_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_post = model_clf.model.embeddings.word_embeddings.weight.detach().cpu().to(torch.float32).numpy()\n",
    "post_post_l = model_clf.model.encoder.layer[1].attention.self.query_proj.weight.detach().cpu().to(torch.float32).numpy()\n",
    "post_post_t = model_clf.clf_head.raw_thresholds.detach().cpu().to(torch.float32).numpy()\n",
    "\n",
    "pre_pre - post_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0651f881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef34b001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a93b3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "post_post_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc6f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pre_t - post_post_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965bea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(post_post_l - pre_pre_l).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d712a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_post_t - pre_pre_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c78573",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_post_t, pre_pre_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094308de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df36b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.optimizer.optimizer.parameter_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55628c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87979f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b023cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64adaf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.raw_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37caa3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f946c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9a4d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f37a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d86b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c150f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3724ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = trainer.optimizer\n",
    "\n",
    "for i, group in enumerate(optimizer.param_groups):\n",
    "    print(f\"Group {i}: lr={group['lr']} | {len(group['params'])} params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dbb964",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(optimizer.param_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babc267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba93410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f3a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.optimizer.optimizer.parameter_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8516ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bdd061",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.raw_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c665d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb754b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe591e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.clf_head.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099b8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58369675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e9cf57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068d9e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train[10000]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c747ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be71495d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da3d6f-a547-40db-b503-f94e435ac92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada8fb66-227b-4647-8377-bdc38bf5beb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1228aab-7ca3-40f1-b3ad-e9ac81d73c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5ca8c8-bdef-484f-950a-5a7627646035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a882547a-6784-4f1e-8a05-b31b426eb35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8310e40a-1e34-4ef3-a0e6-2678bc90e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.iloc[val].FRAMING_CLASS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7e831-3fef-4cab-a1a9-5331faa3b98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002610fa-bea1-4624-a08d-03d199998b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9def06-86d1-4014-b97d-e18b7ad428d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c999f2e7-eb95-462a-aafd-4987a3e7f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a9bd4a-5674-4262-8747-250095b4596a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac76ec-3d1b-4907-bd40-1b0a471d416b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28331fc5-37a4-450a-bf45-74fb5b0e0e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63881f9a-408d-403a-9fc6-651114e6948e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cee4a5-3157-4b47-86c4-487401e1ac10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d913ef-47d3-4308-adb2-5f3546c90815",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794750dc-868d-4b88-934d-aaef5679d567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b609aab6-f5d5-4c03-a626-b4ac1857b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(op.join(output_dir, 'train_val_dataset.ds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc298935-9ed8-4f9c-8ae6-f05575878e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a3aa97-4235-497d-81c5-fe28612416fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4bb258-6f1a-4487-982c-9d03bee40836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b020f-3684-45fd-9628-8cb3e97e5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import list_metrics\n",
    "list_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c871a-0ec1-4bb1-81dc-bdedf92215cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_device_train_batch_size = 1\n",
    "per_device_eval_batch_size=1\n",
    "gradient_accumulation_steps = 5 # @@CH\n",
    "optim = \"paged_adamw_8bit\"\n",
    "save_steps = 500\n",
    "logging_steps = 5\n",
    "learning_rate = 1e-4\n",
    "max_grad_norm = 0.3\n",
    "max_steps = 30_000\n",
    "warmup_ratio = 0.01\n",
    "lr_scheduler_type = \"linear\"\n",
    "eval_steps = 500\n",
    "\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    #dataset_text_field=\"text\",\n",
    "    max_seq_length=max_input_len+100,\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    fp16=True,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=True, #False,#True,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    gradient_checkpointing=True, # @@@@checkpoint\n",
    "    report_to=None,\n",
    "    do_eval=True, #@@@\n",
    "    eval_strategy='steps', #@@@\n",
    "    eval_steps=eval_steps,\n",
    "    #load_best_model_at_end=False,\n",
    "    logging_first_step=True,\n",
    "    #use_cache=False, \n",
    "    #padding_free=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf22ca8-65b3-426e-b607-712b341e1e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65be6eb-b0c4-49f7-9ad4-5631c5c0b692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb6420-4990-40f2-9fc8-756827145958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7cd1ca-cccb-4938-b522-cee5c4e3418f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed887aa-9142-4b9f-9b77-ce9a874dc20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c165816-3d13-490c-9068-732dc57e9213",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f019c91-10ec-42b6-802e-6c857eb3b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import NamedSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f726e-91c2-40e4-8d97-7d3f7218a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6b58ef-3f18-4ec3-a914-de698a1fc6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_.class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb70333-539f-4632-b0e2-6aba8916e472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b244467a-bcd8-4c9c-9bc7-6551c3ba81eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.FRAMING_CLASS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56741774-6319-4bd3-8402-4ee573b7ea73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b0a37f-b6d8-4a30-8492-5906a62a3468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cee19e-7a5d-4b77-917a-3a14a3e772a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e3c9f-942a-40d2-bad3-1ad3a5871432",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d675ba-01cd-4f45-9b43-fa1dd31b182f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b508c-c96d-4b5a-83d6-13eca8ac04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = deberta_clf(**model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd29fb73-809a-479d-b907-e0b8a5b3bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.class_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae07c805-4ec2-43c2-bdb7-ee5505e2f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_clf.clf_head.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a1de65-28ee-4cc6-a085-2a0ac53d52c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_clf.clf_head.raw_thresholds = nn.Parameter(torch.tensor([-1.,2.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38895d25-2025-4c19-9611-79b2882570e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2dfc4-e026-41a9-9a93-a2398ccea8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0391abc-9143-42b5-835f-f2bebb47edfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73358b82-3e87-40c9-a0b3-303e114d54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9ec038-6463-4186-b216-e71ed783a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.class_probabilities.sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d477f-2bbe-4698-9739-0fb3260a6854",
   "metadata": {},
   "outputs": [],
   "source": [
    "op.last_hidden_state[:,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3261cd-387b-40fe-8db6-5659df6f7310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers.modeling_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a1a62c-6ae8-4de4-9a27-23c33e3ceb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_clf.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d24e9b-6923-4959-aea5-0e59ecb8aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(deberta_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f61639a-0f84-49e7-a58f-f3468c83e768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e91a2e-262e-4cf4-971d-8510e1d67f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da35b324-bcac-443f-93a5-8c01425f09a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b66ccc-f535-4331-8799-2b6dc396a29c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
